{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a048ed5",
   "metadata": {},
   "source": [
    "# Install dependencies and import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f059e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f747cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118 11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__, torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91230def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
      "Collecting pyg_lib\n",
      "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/pyg_lib-0.3.1%2Bpt20cu118-cp38-cp38-linux_x86_64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting torch_scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp38-cp38-linux_x86_64.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch_sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp38-cp38-linux_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch_cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.3%2Bpt20cu118-cp38-cp38-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch_spline_conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp38-cp38-linux_x86_64.whl (886 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.0/886.0 kB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch_sparse) (1.6.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch_sparse) (1.22.2)\n",
      "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
      "Successfully installed pyg_lib-0.3.1+pt20cu118 torch_cluster-1.6.3+pt20cu118 torch_scatter-2.1.2+pt20cu118 torch_sparse-0.6.18+pt20cu118 torch_spline_conv-1.2.2+pt20cu118\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "077f368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import os.path as osp\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.datasets import Reddit\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "\n",
    "from networkx.algorithms import community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abb80a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc303a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "path = osp.join('.', 'Reddit')\n",
    "dataset = Reddit(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99a67487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21a4d1",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e89fa5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cab0c503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 602\n",
      "Number of classes: 41\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23decd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 232965\n",
      "Number of edges: 114615892\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')  \n",
    "print(f'Has self-loops: {data.has_self_loops()}')  \n",
    "print(f'Is undirected: {data.is_undirected()}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e86f3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 114615892)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    45,     45,     45, ...,     45,     45,     45],\n",
       "       [   160,    175,    258, ..., 232623, 232625, 232648]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = data.edge_index.numpy()\n",
    "print(edge_index.shape)\n",
    "edge_example = edge_index[:, np.where(edge_index[0]==45)[0]]\n",
    "edge_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a16663",
   "metadata": {},
   "source": [
    "# Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2364e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already send node features/labels to GPU for faster access during sampling:\n",
    "data = dataset[0].to(device, 'x', 'y')\n",
    "\n",
    "kwargs = {'batch_size': 1024, 'num_workers': 6, 'persistent_workers': True}\n",
    "train_loader = NeighborLoader(data, input_nodes=data.train_mask,\n",
    "                              num_neighbors=[25, 10], shuffle=True, **kwargs)\n",
    "\n",
    "subgraph_loader = NeighborLoader(copy.copy(data), input_nodes=None,\n",
    "                                 num_neighbors=[-1], shuffle=False, **kwargs)\n",
    "\n",
    "# No need to maintain these features during evaluation:\n",
    "del subgraph_loader.data.x, subgraph_loader.data.y\n",
    "# Add global node index information.\n",
    "subgraph_loader.data.num_nodes = data.num_nodes\n",
    "subgraph_loader.data.n_id = torch.arange(data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d44fc796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph 0: Data(x=[105702, 602], edge_index=[2, 233317], y=[105702], train_mask=[105702], val_mask=[105702], test_mask=[105702], n_id=[105702], e_id=[233317], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[1024], batch_size=1024)\n",
      "Subgraph 1: Data(x=[106813, 602], edge_index=[2, 236520], y=[106813], train_mask=[106813], val_mask=[106813], test_mask=[106813], n_id=[106813], e_id=[236520], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[1024], batch_size=1024)\n",
      "Subgraph 2: Data(x=[105892, 602], edge_index=[2, 232976], y=[105892], train_mask=[105892], val_mask=[105892], test_mask=[105892], n_id=[105892], e_id=[232976], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[1024], batch_size=1024)\n",
      "Subgraph 3: Data(x=[106564, 602], edge_index=[2, 236272], y=[106564], train_mask=[106564], val_mask=[106564], test_mask=[106564], n_id=[106564], e_id=[236272], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[1024], batch_size=1024)\n",
      "Subgraph 4: Data(x=[105411, 602], edge_index=[2, 230815], y=[105411], train_mask=[105411], val_mask=[105411], test_mask=[105411], n_id=[105411], e_id=[230815], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[1024], batch_size=1024)\n"
     ]
    }
   ],
   "source": [
    "subgraphs_4 = []\n",
    "for i, subgraph in enumerate(train_loader):\n",
    "    print(f'Subgraph {i}: {subgraph}')\n",
    "    subgraphs_4.append(subgraph)\n",
    "    if i == 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = to_networkx(subgraphs_4[0], to_undirected=True) # takes too long to load data\n",
    "# nx.draw_networkx(G, with_labels=False,\n",
    "#                 node_size=200, \n",
    "#                 node_color=sub_graph.y,\n",
    "#                 cmap=\"cool\",\n",
    "#                 font_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b915a4",
   "metadata": {},
   "source": [
    "# GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b99860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < len(self.convs) - 1:\n",
    "                x = x.relu_()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def inference(self, x_all, subgraph_loader):\n",
    "        pbar = tqdm(total=len(subgraph_loader.dataset) * len(self.convs))\n",
    "        pbar.set_description('Evaluating')\n",
    "\n",
    "        # Compute representations of nodes layer by layer, using *all*\n",
    "        # available edges. This leads to faster computation in contrast to\n",
    "        # immediately computing the final representations of each batch:\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            xs = []\n",
    "            for batch in subgraph_loader:\n",
    "                x = x_all[batch.n_id.to(x_all.device)].to(device)\n",
    "                x = conv(x, batch.edge_index.to(device))\n",
    "                if i < len(self.convs) - 1:\n",
    "                    x = x.relu_()\n",
    "                xs.append(x[:batch.batch_size].cpu())\n",
    "                pbar.update(batch.batch_size)\n",
    "            x_all = torch.cat(xs, dim=0)\n",
    "        pbar.close()\n",
    "        return x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b682dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAGE(dataset.num_features, 256, dataset.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c474c",
   "metadata": {},
   "source": [
    "# Main methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88abfe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(total=int(len(train_loader.dataset)))\n",
    "    pbar.set_description(f'Epoch {epoch:02d}')\n",
    "\n",
    "    total_loss = total_correct = total_examples = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * batch.batch_size\n",
    "        total_correct += int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_examples += batch.batch_size\n",
    "        pbar.update(batch.batch_size)\n",
    "    pbar.close()\n",
    "\n",
    "    return total_loss / total_examples, total_correct / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    y_hat = model.inference(data.x, subgraph_loader).argmax(dim=-1)\n",
    "    y = data.y.to(y_hat.device)\n",
    "\n",
    "    accs = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        accs.append(int((y_hat[mask] == y[mask]).sum()) / int(mask.sum()))\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde43bb0",
   "metadata": {},
   "source": [
    "# Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dcda75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|██████████| 153431/153431 [00:06<00:00, 22376.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 0.5071, Approx. Train: 0.8945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [00:48<00:00, 9583.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train: 0.9532, Val: 0.9522, Test: 0.9501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 153431/153431 [00:05<00:00, 27000.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Loss: 0.5186, Approx. Train: 0.9225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [00:48<00:00, 9613.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train: 0.9478, Val: 0.9450, Test: 0.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|██████████| 153431/153431 [00:05<00:00, 27148.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03, Loss: 0.5010, Approx. Train: 0.9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [00:48<00:00, 9618.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train: 0.9567, Val: 0.9516, Test: 0.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|██████████| 153431/153431 [00:05<00:00, 27012.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04, Loss: 0.4907, Approx. Train: 0.9276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [00:48<00:00, 9631.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train: 0.9589, Val: 0.9530, Test: 0.9514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: 100%|██████████| 153431/153431 [00:05<00:00, 26323.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05, Loss: 0.5361, Approx. Train: 0.9285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [00:48<00:00, 9705.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train: 0.9603, Val: 0.9503, Test: 0.9516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|██████████| 153431/153431 [00:05<00:00, 25751.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06, Loss: 0.5411, Approx. Train: 0.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [00:47<00:00, 9825.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train: 0.9606, Val: 0.9512, Test: 0.9513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07: 100%|██████████| 153431/153431 [00:05<00:00, 26536.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07, Loss: 0.5213, Approx. Train: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [00:47<00:00, 9808.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train: 0.9640, Val: 0.9509, Test: 0.9522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08: 100%|██████████| 153431/153431 [00:05<00:00, 26746.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08, Loss: 0.5036, Approx. Train: 0.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [00:48<00:00, 9648.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train: 0.9636, Val: 0.9519, Test: 0.9521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09: 100%|██████████| 153431/153431 [00:05<00:00, 26738.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09, Loss: 0.5297, Approx. Train: 0.9329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [00:48<00:00, 9581.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train: 0.9635, Val: 0.9507, Test: 0.9506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 153431/153431 [00:05<00:00, 27099.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.5687, Approx. Train: 0.9320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [00:48<00:00, 9684.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train: 0.9626, Val: 0.9515, Test: 0.9505\n",
      "Median time per epoch: 54.0749s\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "for epoch in range(1, 11):\n",
    "    start = time.time()\n",
    "    loss, acc = train(epoch)\n",
    "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}')\n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    print(f'Epoch: {epoch:02d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
    "          f'Test: {test_acc:.4f}')\n",
    "    times.append(time.time() - start)\n",
    "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18095932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
